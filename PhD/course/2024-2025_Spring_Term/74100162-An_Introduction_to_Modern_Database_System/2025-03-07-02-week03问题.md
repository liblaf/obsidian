---
date: 2025-03-07T10:48:00+08:00
modified: 2025-09-20T23:07:37+08:00
tags:
  - PhD/Course/An_Introduction_to_Modern_Database_System
title: Week 03 问题
---

## (B) CHORUS: Foundation Models for Unified Data Discovery and Exploration

> [!QUESTION]
>
> 1. 传统数据发现 (Data Discovery) 和探索 (Data Exploration) 存在哪些主要挑战?

- 分析师需花费大量时间 (约 40%) 在数据加载和清洗上.
- 企业内 60-70% 的数据未被利用, 成为 "暗数据".
- 现有工具依赖任务专用模型, 需大量标注数据 (如 10 万至百万级样本).
- 异构数据集成困难, 自动化程度不足, 导致数据发现效率低下.

> [!QUESTION] 2. 本文提出的 Chorus 系统如何利用基础模型 (Foundation Models) 改进数据发现任务?

CHORUS 通过基础模型 (如 GPT-3.5) 的泛化能力, 统一处理多个数据管理任务:

- 将任务转化为自然语言输入输出, 无需任务专用训练.
- 支持零样本 (Zero-shot) 和少样本 (Few-shot) 学习, 减少对标注数据的依赖.
- 通过上下文信息流 (如前一任务结果影响后续任务) 提升任务间协同效果.

> [!QUESTION] 3. Chorus 采用了哪些关键的任务处理流程?

- **任务顺序执行:** 前一任务的输出作为后续任务的上下文输入.
- **模型输入构建:** 包括指令、示例、数据样本、元数据、任务特定知识和输出前缀.
- **后处理与错误修正:** 通过约束检查 (如类型合法性) 和 "Anchoring" 技术修复错误.
- **统一架构设计:** 允许跨任务信息共享, 提升整体效率.

> [!QUESTION] 4. 论文中提出的 "Anchoring" 技术是什么? 如何用于错误修正?

- **定义:** Anchoring 是一种通过虚构历史输入修正模型幻觉 (Hallucination) 的技术.
- **步骤:**
  1. 检测到输出违反约束 (如无效类别) 时终止当前对话.
  2. 启动新对话, 插入虚构的 "正确历史" 输入 (如用最近合法类别替换错误输出).
  3. 模型基于干净输入重新生成结果, 避免错误传播.

> [!QUESTION] 5. Chorus 如何构建 Prompt 输入, 以适应不同任务的需求?

Prompt 由六部分构成:

- **指令:** 任务的自然语言描述 (如 "为表格选择 DBPedia 类别").
- **演示:** 少量示例 (如带标注的表格样本).
- **数据样本:** 序列化的表格数据 (如 CSV 片段).
- **元数据:** 列名、键等模式信息.
- **任务特定知识:** 如允许的输出类别列表.
- **前缀:** 引导输出格式 (如 DBPedia URI 前缀或 Pandas 代码片段).

> [!QUESTION] 6. Chorus 在表分类检测 (Table-class detection) 任务中的表现如何? 如何与现有方法比较?

- **监督实验:** 在 T2Dv2 数据集上, CHORUS 的 F1 为 0.926, 显著优于 DoDuo-Wiki (0.757) 和 TaBERT (0.746).
- **非监督实验:** 允许预测全部 768 个 DBPedia 类别时, 93% 的结果正确, 其中 10% 优于专家标注.
- **效率:** 处理速度达 31 表/秒, 成本为 2.5 美元/100 表.

> [!QUESTION] 7. 在连接列预测 (Join-column prediction) 任务中, 与其他方法对比, Chorus 效果如何?

- **手动评估 (300 样本):** CHORUS 的 F1 为 0.895, 高于 Trifacta Wrangler (0.823)、Levenshtein 距离 (0.718) 和 Jaccard 相似性 (0.575).
- **全数据集 (24,579 样本):** F1 达 0.912, 证明其扩展性和稳定性.
- **优势:** 通过自然语言建模捕捉语义关联, 超越传统基于名称相似性的方法.
